{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Prep_Pipe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKT8s7iRPHuT",
        "colab_type": "code",
        "outputId": "2ab17fa9-7c12-45d9-9ee7-7fd286b979e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43oMMj0GPO6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import groupby\n",
        "from statistics import median,mean,stdev\n",
        "from scipy import stats as s\n",
        "from warnings import simplefilter\n",
        "import math\n",
        "from warnings import simplefilter\n",
        "simplefilter(action='ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXoFkg2RPw9p",
        "colab_type": "text"
      },
      "source": [
        "Reading and Preparing Input from Project_Data\n",
        "\n",
        "Parameters raw_to_summary:\n",
        "1.   input_dir\n",
        "\n",
        "> Specify the input directory, which contains subdirectories for each Fold. The Fold1_Outcomes.csv,Fold2_Outcomes.csv,Fold3_Outcomes.csv,Fold4_Outcomes.csv are assumed to be under the input directory. Same structure as given in Project_Data.zip.\n",
        "\n",
        "2.   output_dir\n",
        "\n",
        "> Output directory where the data which is processed to be stored as csv.\n",
        "\n",
        "Note: Please make sure that *output_dir* is not a sub folder inside *input_dir*.\n",
        "\n",
        "3. summary_type\n",
        "\n",
        "\n",
        "> The type of summarization for raw_data, examples of summary_type is 'mean','mode','standard_deviation'.\n",
        "\n",
        "\n",
        "\n",
        "One file for each type of summary_type is obtained. Each file contians all the patients summarized values. The csv has records ordered as per folds. The fold outcome csv files are from the Imputed Outcome Files provided in luminus.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijiN98fOPfYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### All attributes/features we need to look in raw data file for summarizing \n",
        "def raw_to_summary(input_dir,output_dir,summary_type):\n",
        "  attr_list = [ \"RecordID\", \"Age\", \"Gender\", \"Height\", \"ICUType\", \"Weight\",\n",
        "                \"Albumin\", \"ALP\", \"ALT\", \"AST\", \"Bilirubin\", \"BUN\", \"Cholesterol\",\n",
        "                \"Creatinine\", \"DiasABP\", \"FiO2\", \"GCS\", \"Glucose\", \"HCO3\", \"HCT\",\n",
        "                \"HR\", \"K\", \"Lactate\", \"Mg\", \"MAP\", \"MechVent\", \"Na\", \"NIDiasABP\",\n",
        "                \"NIMAP\", \"NISysABP\", \"PaCO2\", \"PaO2\", \"pH\", \"Platelets\", \n",
        "                \"RespRate\", \"SaO2\", \"SysABP\", \"Temp\", \"TroponinI\", \"TroponinT\",\n",
        "                \"Urine\", \"WBC\"]\n",
        "\n",
        "  # Give the root folder which contains Fold1,Fold2,Fold3,Fold4 of the data\n",
        "  ##Change Directory where raw files are under their respective folders\n",
        "  ## Sorting the folders so that folds are read as per order\n",
        "  ## Each file under fold is read as per sorted order\n",
        "  ## One directory for all patients\n",
        "  ## each patient data is a dictionary of feature: values, where values are stored as list of list\n",
        "\n",
        "  dir_path = input_dir\n",
        "  #\"/Users/mahendrensundararajan/Desktop/Project_Data/\"\n",
        "  patients_dir = {}\n",
        "  c = 0\n",
        "  mylist = []\n",
        "  for root, dirs, files in sorted(os.walk(dir_path, topdown=False)):\n",
        "      for name in sorted(files):\n",
        "          # Checking the filename it is has txt extension it is taken up for processing\n",
        "          if 'txt' in name:\n",
        "              mylist.append(name)\n",
        "              f = open(os.path.join(root, name), 'r')\n",
        "              rows = []\n",
        "              for row in f.readlines():\n",
        "                  rows.append(row)\n",
        "              p1 = {}\n",
        "              # Adding the time of each measurement\n",
        "              p1[\"time\"] = []\n",
        "              for var in attr_list:\n",
        "                  p1[var] = []\n",
        "              for row in rows[1:]:\n",
        "                  p1[\"time\"].append(row.split(',')[0])\n",
        "                  p1[row.split(',')[1]].append([row.split(',')[0],row.rstrip().split(',')[2]])\n",
        "              patients_dir[c] = p1\n",
        "              c+=1\n",
        "\n",
        "  dup_dir = patients_dir.copy()\n",
        "  # Iterate over the patients dictionary for summarizing each feature\n",
        "  for key, value in dup_dir.items():\n",
        "      # As each value gives the patient dictionary the iterating on the attributes of that patient\n",
        "      for key_,val in value.items():\n",
        "      # Ignoring the time when measurement is made\n",
        "          if 'time' not in key_:\n",
        "          # Some features may not have any values replace it with NA \n",
        "              if isinstance(val,(list)) and len(val) == 0:\n",
        "                  value[key_]='NA'\n",
        "          # If only one value for a feature is available then take that value\n",
        "              elif isinstance(val,(list)) and len(val) == 1:\n",
        "                  templist = val\n",
        "                  res_ = [el[1] for el in templist]\n",
        "                  value[key_] = res_[0]\n",
        "          # When feature has many values, then different types of summarization can be done like mean, median,mode, stddev\n",
        "              elif isinstance(val,(list)) and len(val) > 1:\n",
        "                  templist = val\n",
        "                  res = [float(el[1]) for el in templist]\n",
        "                  if 'stddev' in summary_type:\n",
        "                    value[key_] = stdev(res)\n",
        "                  elif 'mean' in summary_type:\n",
        "                    value[key_] = sum(res)/len(res)\n",
        "                  elif 'mode' in summary_type:\n",
        "                    # If multiple modes then take the first mode\n",
        "                    value[key_] = float(s.mode(res)[0])\n",
        "  \n",
        "  ## Create a dataframe then add each patient, where each feature is a summary statistic\n",
        "  my_df  = pd.DataFrame(columns = attr_list)\n",
        "  for key, value in patients_dir.items():\n",
        "    my_df = my_df.append({'RecordID':value['RecordID'],\n",
        "    'Age':value['Age'],\n",
        "    'Gender':value['Gender'],\n",
        "    'Height':value['Height'],\n",
        "    'ICUType':value['ICUType'],\n",
        "    'Weight':value['Weight'],\n",
        "    'Albumin':value['Albumin'],\n",
        "    'ALP':value['ALP'],\n",
        "    'ALT':value['ALT'],\n",
        "    'AST':value['AST'],\n",
        "    'Bilirubin':value['Bilirubin'],\n",
        "    'BUN':value['BUN'],\n",
        "    'Cholesterol':value['Cholesterol'],\n",
        "    'Creatinine':value['Creatinine'],\n",
        "    'DiasABP':value['DiasABP'],\n",
        "    'FiO2':value['FiO2'],\n",
        "    'GCS':value['GCS'],\n",
        "    'Glucose':value['Glucose'],\n",
        "    'HCO3':value['HCO3'],\n",
        "    'HCT':value['HCT'],\n",
        "    'HR':value['HR'],\n",
        "    'K':value['K'],\n",
        "    'Lactate':value['Lactate'],\n",
        "    'Mg':value['Mg'],\n",
        "    'MAP':value['MAP'],\n",
        "    'MechVent':value['MechVent'],\n",
        "    'Na':value['Na'],\n",
        "    'NIDiasABP':value['NIDiasABP'],\n",
        "    'NIMAP':value['NIMAP'],\n",
        "    'NISysABP':value['NISysABP'],\n",
        "    'PaCO2':value['PaCO2'],\n",
        "    'PaO2':value['PaO2'],\n",
        "    'pH':value['pH'],\n",
        "    'Platelets':value['Platelets'],\n",
        "    'RespRate':value['RespRate'],\n",
        "    'SaO2':value['SaO2'],\n",
        "    'SysABP':value['SysABP'],\n",
        "    'Temp':value['Temp'],\n",
        "    'TroponinI':value['TroponinI'],\n",
        "    'TroponinT':value['TroponinT'],\n",
        "    'Urine':value['Urine'],\n",
        "    'WBC':value['WBC']},ignore_index=True)\n",
        "\n",
        "  # reading y and sorting by patients_id on each fold\n",
        "  # As data files are read in order of folds and order of filenames(record_id),\n",
        "  # the y label is also read as per fold and sorted on filename (record_id)\n",
        "  # Appending it to the patients dataframe\n",
        "  # Finally a single dataframe containing all the patients, ordered on folds, is got \n",
        "  \n",
        "  filepath = dir_path + 'Fold1_Outcomes.csv'\n",
        "  fold1_out = pd.read_csv(filepath)\n",
        "  filepath = dir_path + 'Fold2_Outcomes.csv'\n",
        "\n",
        "  fold2_out = pd.read_csv(filepath)\n",
        "  filepath = dir_path + 'Fold3_Outcomes.csv'\n",
        "\n",
        "  fold3_out = pd.read_csv(filepath)\n",
        "  filepath = dir_path + 'Fold4_Outcomes.csv'\n",
        "\n",
        "  fold4_out = pd.read_csv(filepath)\n",
        "\n",
        "  fold1_out.sort_values(by=['RecordID'],inplace=True)\n",
        "  fold2_out.sort_values(by=['RecordID'],inplace=True)\n",
        "  fold3_out.sort_values(by=['RecordID'],inplace=True)\n",
        "  fold4_out.sort_values(by=['RecordID'],inplace=True)\n",
        "\n",
        "  frames = [fold1_out, fold2_out, fold3_out,fold4_out]\n",
        "  result = pd.concat(frames,ignore_index=True)\n",
        "  result.sort_values(by=['RecordID'],inplace=True)\n",
        "  my_df['Length_of_stay'] = result['Length_of_stay']\n",
        "  my_df['In-hospital_death'] = result['In-hospital_death']\n",
        "  fullname = os.path.join(output_dir,'summary_'+summary_type+'.csv')  \n",
        "  my_df.to_csv(fullname,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL2pa7riPqdY",
        "colab_type": "text"
      },
      "source": [
        "Modify the input_dir or output_dir variable for respective file paths.\n",
        "\n",
        "Code to generate summarized files of each summary_type.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lDI8WunPkSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum_dict = {}\n",
        "sum_dict[0] = 'mean'\n",
        "sum_dict[1] = 'mode'\n",
        "sum_dict[2] = 'stddev'\n",
        "\n",
        "# Please enter the output and input folder paths here.\n",
        "input_dir = './Project_Data/'\n",
        "output_dir = './Prep_Data/'\n",
        "\n",
        "for k,v in sum_dict.items():\n",
        "  raw_to_summary(input_dir,output_dir,v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waIPygZzJky-",
        "colab_type": "text"
      },
      "source": [
        "This Code creates the design matrix with additional columns that are standard_deviation of corresponding features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elayhl-5JMYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add Standard deviation of certain features to the dataset and use it as design matrix\n",
        "df = pd.read_csv(output_dir+'summary_stddev.csv')\n",
        "my_df = pd.read_csv(output_dir+'summary_mean.csv')\n",
        "\n",
        "# The following columns are chosen based on Exploratory Data Analysis  \n",
        "df = df[['RecordID','DiasABP', 'FiO2', 'GCS', 'HR', 'MAP','NIDiasABP','NIMAP','SysABP','Temp','Urine', 'Weight']]\n",
        "df.sort_values(by=['RecordID'],inplace=True)\n",
        "\n",
        "# Deign_matrix is summary_mean along with stddev of some timeseries columns\n",
        "my_df['DiasABP_std'] = df['DiasABP']\n",
        "my_df['FiO2_std'] = df['FiO2']\n",
        "my_df['GCS_std'] = df['GCS']\n",
        "my_df['HR_std'] = df['HR']\n",
        "my_df['MAP_std'] = df['MAP']\n",
        "my_df['NIDiasABP_std'] = df['NIDiasABP']\n",
        "my_df['NIMAP_std'] = df['NIMAP']\n",
        "my_df['SysABP_std'] = df['SysABP']\n",
        "my_df['Temp_std'] = df['Temp']\n",
        "my_df['Urine_std'] = df['Urine']\n",
        "my_df['Weight_std'] = df['Weight']\n",
        "\n",
        "fullname = os.path.join(output_dir,'combined_mean_std.csv')  \n",
        "my_df.to_csv(fullname,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}